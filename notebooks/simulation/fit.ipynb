{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "import scipy.special as sp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Contains functions used in fitting the power-law, exponential, log-normal,\n",
    "Weibull (stretched exponential), and power-law with exponential cutoff, as well\n",
    "as plpval() to find a p-value for the power-law fit. All should be called\n",
    "directly. All distributions are discrete.\n",
    "\n",
    "This code is directly copied from https://github.com/adbroido/SFAnalysis/blob/master/code/fit.py\n",
    "Citation: Anna D. Broido & Aaron Clauset, \"Scale-free networks are rare\", Nature Communications 10, 1017 (2019).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl(x):\n",
    "    \"\"\" Fits a tail-conditional power-law to a data set. This implements brute\n",
    "    force optimization (grid search) instead of using a built in optimizer. The\n",
    "    grid on alpha runs from alstart to alstart+shift. This is based on Aaron's\n",
    "    plfit.m Matlab code (http://tuvalu.santafe.edu/~aaronc/powerlaws/).\n",
    "    \n",
    "    This code is directly copied from https://github.com/adbroido/SFAnalysis/blob/master/code/fit.py\n",
    "    Citation: Anna D. Broido & Aaron Clauset, \"Scale-free networks are rare\", Nature Communications 10, 1017 (2019).\n",
    "\n",
    "    Input:\n",
    "        x           ndarray, ndim = 1, dtype = integer\n",
    "    Output:\n",
    "        alpha        float, exponent on x, must be > 1\n",
    "        xmin         int, starting point for power law tail, must be >= 1\n",
    "        ntail        int, number of datapoints above (and including) xmin\n",
    "        L            float, log likelihood of the returned fit\n",
    "        ks           float, goodness of fit statistic (Kolmogorov-Smirnov)\n",
    "    \n",
    "    \"\"\"\n",
    "    # find the and sort unique possible xmin values\n",
    "    xminV = np.trim_zeros(np.unique(x))\n",
    "    # initialize array of the fits for every xmin\n",
    "    fitV = np.zeros([len(xminV),2])\n",
    "\n",
    "    start_time = time.time()\n",
    "    # initialize vector of constants\n",
    "    # where the xmins start\n",
    "    xminprev = min(xminV) - 1\n",
    "    # initialize array of possible alpha values\n",
    "    alstart = 1.01\n",
    "    shift = 9.50\n",
    "    alphaV = np.arange(alstart,alstart+shift,0.01)\n",
    "    zetaV = sp.zeta(alphaV)\n",
    "    constV = zetaV\n",
    "    # shift up to start at the smallest xmin\n",
    "    for j in range(xminprev):\n",
    "        constV += -(1+j)**(-alphaV)\n",
    "\n",
    "    # loop over the xmin values at find the best fit at each\n",
    "    for i in range(len(xminV)):\n",
    "        xmin = xminV[i]\n",
    "        xtail = x[x>=xmin]\n",
    "        ntail = len(xtail)\n",
    "        # optimize over alpha\n",
    "        # find the corresponding array of conditional log likelihoods\n",
    "        Ls = -alphaV*np.sum(np.log(xtail)) - ntail*np.log(constV)\n",
    "        # pull out the location of the best fit alpha\n",
    "        aind = Ls.argmax()\n",
    "        # find what alpha value is at this index\n",
    "        alpha = alphaV[aind]\n",
    "        # compute the KS statistic\n",
    "        # theoretical cdf\n",
    "        cdf = np.cumsum(range(np.min(xtail), np.max(xtail)+1)**(-alpha)/constV[aind])\n",
    "        #  binned data\n",
    "        xhist = np.histogram(xtail,range(np.min(xtail), np.max(xtail)+2))\n",
    "        # empirical cdf\n",
    "        edf = np.cumsum(xhist[0])/float(ntail)\n",
    "        # KS stat\n",
    "        ks = np.max(np.abs(cdf-edf))\n",
    "        # add this KS stat and alpha to the array of fits\n",
    "        fitV[i] = np.array([ks, alpha])\n",
    "        # update the constants\n",
    "        for j in range(xmin-xminprev):\n",
    "            constV += -(xmin+j)**(-alphaV)\n",
    "        xminprev = xmin\n",
    "\n",
    "\n",
    "    # pull out the index of the smallest KS stat\n",
    "    ksind = fitV[:,0].argmin()\n",
    "    ks = fitV[ksind,0]\n",
    "    # find the corresponding xmin\n",
    "    xmin = xminV[ksind]\n",
    "    # find the corresponding alpha\n",
    "    alpha = fitV[ksind,1]\n",
    "    # evaluate the likelihood here\n",
    "    xtail = x[x>=xmin]\n",
    "    ntail = len(xtail)\n",
    "    start_time = time.time()\n",
    "    const = sp.zeta(alpha) - np.sum(np.arange(1,xmin)**(-alpha))\n",
    "    L = -alpha * np.sum(np.log(xtail)) - ntail*np.log(const)\n",
    "    # print \"-------%s seconds -----------\" %(time.time()-start_time)\n",
    "    # print \"alpha = %s\" %alpha\n",
    "    # print \"xmin = %s\" %xmin\n",
    "    return [alpha,xmin, ntail, L, ks]\n",
    "\n",
    "def plpval(x, alpha, xmin, gof):\n",
    "    \"\"\" Finds p-value for the power-law fit using a KS test. This is based on\n",
    "    Aaron's plpva.m Matlab code (http://tuvalu.santafe.edu/~aaronc/powerlaws/).\n",
    "    \n",
    "    This code is directly copied from https://github.com/adbroido/SFAnalysis/blob/master/code/fit.py\n",
    "    Citation: Anna D. Broido & Aaron Clauset, \"Scale-free networks are rare\", Nature Communications 10, 1017 (2019).\n",
    "    \n",
    "    Input:\n",
    "        x            ndarray, ndim = 1, dtype = integer\n",
    "        alpha        float, exponent on x, must be > 1\n",
    "        xmin         int, starting point for power law tail, must be >= 1\n",
    "        gof           float, goodness of fit statistic (Kolmogorov-Smirnov)\n",
    "    Output:\n",
    "        p            p-value of the returned fit (reject PL hypothesis for p<0.1)\n",
    "    \"\"\"\n",
    "    # set desired precision level in p-value\n",
    "    eps = 0.01\n",
    "    #num_resamps = int(np.ceil((1./4)*eps**(-2)))\n",
    "    num_resamps = 1000\n",
    "    bootstraps = np.zeros(num_resamps)\n",
    "    n = len(x)\n",
    "    xmax = np.max(x)\n",
    "    tailinds = x>=xmin\n",
    "    xtail = x[tailinds]\n",
    "    xhead = x[~tailinds]\n",
    "    ntail = len(xtail)\n",
    "    nhead = len(xhead)\n",
    "    ptail = float(ntail)/n\n",
    "    mmax = 20*xmax\n",
    "    # set the tail of the pdf\n",
    "    #const_tail = ic.plconst(np.array(alpha),xmin)\n",
    "    const_tail = sp.zeta(alpha) - np.sum(np.arange(1,xmin)**(-alpha))\n",
    "    pdf_tail = np.arange(xmin,mmax+1)**(-alpha)/const_tail # i.e.; end at mmax\n",
    "    # pad this with zeros (rewrite if we don't need to do this)\n",
    "    pdf = np.zeros(mmax+1)\n",
    "    pdf[xmin:] = pdf_tail\n",
    "    # clean up in case this is a huge array\n",
    "    del pdf_tail\n",
    "    # set the cdf. rows are x-val or cdf(xval). So cdf(x=10) is cdf[1,10]\n",
    "    cdf = np.array( [ np.arange(mmax+1), np.cumsum(pdf) ] )\n",
    "    # tack on a last entry\n",
    "    cdf = np.concatenate( (cdf , np.array([[mmax+1,1]]).T) , axis = 1 )\n",
    "\n",
    "    # semi-parametric bootstrap\n",
    "    starttime = time.time()\n",
    "    for resamp_ind in range(num_resamps):\n",
    "        # non-parametric bootstrap from the head of x\n",
    "        # count how many of n random numbers are in the head, based on the probability of being in the head of x\n",
    "        nnewhead = n\n",
    "        while nnewhead >= n:\n",
    "            nnewhead = np.sum(np.random.rand(n)>ptail)\n",
    "        headinds = np.array([np.floor(nhead*np.random.rand(nnewhead))],dtype=int)\n",
    "        newhead = xhead[headinds][0]\n",
    "        nnewtail  = n-nnewhead\n",
    "\n",
    "        # parametric bootstrap for the powerlaw tail\n",
    "        rtail = np.sort(np.random.rand(nnewtail))\n",
    "        newtail = np.zeros(nnewtail, dtype = int)\n",
    "        indrtail = 0\n",
    "        indnewtail = 0\n",
    "        for xval in range(xmin, mmax+2):\n",
    "            while (indrtail < len(rtail)) and (rtail[indrtail] <= cdf[1, xval]):\n",
    "                indrtail += 1\n",
    "            newtail[indnewtail:indrtail] = xval\n",
    "            indnewtail = indrtail\n",
    "            if indnewtail > nnewtail:\n",
    "                break\n",
    "        # combine into new sample\n",
    "        newx = np.concatenate((newhead, newtail))\n",
    "        if (newx == np.zeros_like(newx)).all():\n",
    "            import pdb; pdb.set_trace()\n",
    "        # fit this new sample\n",
    "        [newalpha, newxmin, newntail, newLpl, newgof] = pl(newx)\n",
    "        # print where we are\n",
    "        current_p = np.sum(bootstraps[0:resamp_ind]>=gof)/(float(resamp_ind+1))\n",
    "        # print \"[%s]    p = %f\" %(resamp_ind, current_p)\n",
    "        # store gof stat\n",
    "        bootstraps[resamp_ind] = newgof\n",
    "        # if it's taking forever and we can end, do it\n",
    "        if time.time() - starttime > 500:\n",
    "            if resamp_ind > num_resamps/20.:\n",
    "                if current_p<0.05 or current_p>0.5:\n",
    "                    print(\"current p = %s   elapsed time = %s\" %(current_p, time.time()-starttime))\n",
    "                    return current_p\n",
    "    p = np.sum(bootstraps>=gof)/float(num_resamps)\n",
    "    print (\"p = %.3f   elapsed time = %s\" %(p, time.time()-starttime))\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.379   elapsed time = 23.114078998565674\n"
     ]
    }
   ],
   "source": [
    "# x = np.random.power(2,1000)\n",
    "# x *= 1000\n",
    "# x = np.array([round(i) for i in x])\n",
    "x = np.array([8, 10, 18, 8, 12, 34, 15, 25, 31, 48, 46, 48, 40, 32, 34, 35, 19, 21, 29, 20, 28, 35, 27, 21, 17, 20, 21, 24, 22, 20, 20, 19, 19, 21, 13, 29, 31, 17, 12, 13, 16, 13, 16, 11, 14, 12, 14, 14, 10, 14, 12, 11, 11, 11, 14, 13, 14, 11, 14, 12, 15, 13, 15, 10, 14, 10, 11, 13, 10, 12, 12, 10, 10, 11, 12, 10, 9, 13, 10, 9, 10, 10, 9, 9, 9, 9, 10, 10, 9, 10, 11, 9, 9, 11, 10, 9, 9, 9, 9, 9])\n",
    "[alpha, xmin, ntail,  L, ks] = pl(x)\n",
    "p = plpval(x,alpha, xmin, ks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cci_dt] *",
   "language": "python",
   "name": "conda-env-cci_dt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
